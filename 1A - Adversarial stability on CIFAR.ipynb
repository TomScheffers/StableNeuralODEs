{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability on CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train for stability, we leverage two methods in this research: \n",
    "1. Numerical estimation of Lyapunov exponent\n",
    "2. Runge kutta divergence\n",
    "\n",
    "1 requires adaptation of the solver, where in 2 we only need parameters from the RK4 integrator. The code adaptation to the base (see notebook 0) are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. In the solver, we perform the numerical estimation of the Lyapunov exponent:\n",
    "class FixedStepNumericalLyapunovSolverV2():\n",
    "    def __init__(self, f, t0, t1, method, steps=None, step_size=None, verbose=False, eps=1, n=2):\n",
    "        self.name = \"FixedStepNumericalLyapunovSolverV2\"\n",
    "        self.f = f\n",
    "        self.t0 = t0\n",
    "        self.t1 = t1\n",
    "        self.method = method\n",
    "        self.eps, self.n = eps, n\n",
    "        self.vecs = [None]\n",
    "        self.loops = 3\n",
    "        self.diff = [None for _ in range(n)]\n",
    "        self.lyapunov = True\n",
    "\n",
    "        # Define the step sizes h to go from t0 to t1\n",
    "        assert steps or step_size, \"Either steps or step size should be defined!\"\n",
    "        if steps:\n",
    "            self.hs = [(t1 - t0) / steps for s in range(steps)]\n",
    "        else:\n",
    "            assert step_size <= (t1 - t0), \"Step size should be smaller than integration time!\"\n",
    "            self.hs = [step_size for _ in range(int((t1 - t0) / step_size))]\n",
    "            # Add the residual in the last step, if required\n",
    "            if (t1 - t0) % step_size != 0:\n",
    "                self.hs.append((t1 - t0) - sum(self.hs))\n",
    "        if verbose:\n",
    "            print(\"This solver will be using the following time deltas:\", self.hs)\n",
    "            print(\"This solver will require\", self.method.order * len(self.hs), \"gradient evaluations\")\n",
    "\n",
    "    def batch_normalize(self, p):\n",
    "        return p / torch.norm(p.view(p.size(0), -1), p=2, dim=1)[:, None, None, None]\n",
    "\n",
    "    def reset_vec(self, y):\n",
    "        # Random vector and its norm along the batch size\n",
    "        ps = [torch.randn_like(y) for _ in range(self.n)]\n",
    "        self.vecs = [self.batch_normalize(p) for p in ps]\n",
    "\n",
    "    def integrate(self, y, reset=False):\n",
    "        # First we integrate the original system y\n",
    "        t = self.t0\n",
    "        for h in self.hs:\n",
    "            y = self.method.step(self.f, t, h, y)\n",
    "            t += h\n",
    "\n",
    "        if self.lyapunov:\n",
    "            # Then we iteratively determine the Lyapunov vector for the batch\n",
    "            self.exp = 0\n",
    "            \n",
    "            # First we make N versions of y by randomly mutating\n",
    "            self.reset_vec(y)\n",
    "            self.diff = []\n",
    "            for l in range(self.loops):\n",
    "                # Re-do the orbit seperation each loop\n",
    "                ys = [y + self.eps * self.vecs[i] for i in range(self.n)]\n",
    "\n",
    "                # Concatenate the y to batch the vectors\n",
    "                yb = torch.cat(ys, dim=0)\n",
    "                \n",
    "                # Integrate the system for both y and ys\n",
    "                t = self.t0\n",
    "                for h in self.hs:\n",
    "                    yb = self.method.step(self.f, t, h, yb)\n",
    "                    t += h\n",
    "                yl = torch.chunk(yb, self.n, dim=0)\n",
    "                \n",
    "                # Calculate the seperation\n",
    "                for i in range(self.n):\n",
    "                    # Calculate the difference minus the projection of earlier vectors (ealier vector, scaled by the dot product of yl and earlier vectors)\n",
    "                    diff = yl[i] - y\n",
    "                    proj = sum([self.vecs[j] * (diff * self.vecs[j]).sum([1,2,3])[:, None, None, None] for j in range(0, i)])\n",
    "                    diff = (diff - proj)\n",
    "                \n",
    "                if l < self.loops - 1:\n",
    "                    # The Lyapunov is the normalized vector in the difference direction\n",
    "                    self.vecs[i] = self.batch_normalize(diff).detach()\n",
    "                else:\n",
    "                    self.diff.append(diff)\n",
    "                    # Calculate exponent at last divergence\n",
    "                    self.exp += 1 / t * torch.log(torch.norm(diff.view(diff.size(0), -1), p=2, dim=1) / self.eps + 1e-10).mean()\n",
    "        else:\n",
    "            self.exp = None\n",
    "        return y\n",
    "\n",
    "\n",
    "# 2. Besides the estimation of the next point, this integrator also returns the (batch_mean) L2 norm:\n",
    "class K2K3L2DistRungeKutta4():\n",
    "    name = \"K2K3L2DistRungeKutta4\"\n",
    "    order = 4\n",
    "    def step(f, t, dt, y):\n",
    "        k1 = f(t, y)\n",
    "        k2 = f(t + dt / 2,  y + dt * k1 / 2)\n",
    "        k3 = f(t + dt / 2,  y + dt * k2 / 2)\n",
    "        k4 = f(t + dt,      y + dt * k3)\n",
    "        return y + dt * (k1 + 2 * k2 + 2 * k3 + k4) / 6, ((k2 - k3) ** 2).mean(0).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Stability\n",
    "\n",
    "Adversarial attacks are one way to test for stability in Neural networks. In the paper, we use the following adversarial attacks (code defined in utils.attacks)\n",
    "1. Fast Gradient Sign Method (FGSM)\n",
    "2. Projected Gradient Descent (PGD)\n",
    "3. DeepFool\n",
    "4. Gaussian noise\n",
    "5. Salt and pepper noise\n",
    "6. Simple black box adversarial attack (SIMBA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "This solver will be using the following time deltas: [0.5, 0.5]\n",
      "This solver will require 2 gradient evaluations\n",
      "This model is using 7847946 parameters\n",
      "This model is using 12 Conv layers\n",
      "\n",
      "FixedStepSolver-Euler-2Step-eps1-leRegNone-VecsNone-Run0\n",
      "Epoch: 1 / 20 | Time per iter 0.028 | Train acc: 49.115 | Train exps: 0.000 | Test acc: 63.001 | Test exps: 0.000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/cifar10/FixedStepSolver-Euler-2Step-eps1-leRegNone-VecsNone-Run0.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-57c6c7ced7e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Save the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'checkpoints/cifar10/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"-\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"-\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpost_fix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                 \u001b[0mbest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomsc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \"\"\"\n\u001b[1;32m--> 219\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomsc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/cifar10/FixedStepSolver-Euler-2Step-eps1-leRegNone-VecsNone-Run0.pth'"
     ]
    }
   ],
   "source": [
    "import sys, time, torch\n",
    "from utils.training.training_ops import Average, accuracy, loader_accuracy\n",
    "\n",
    "# Make the training / testing loaders\n",
    "from utils.training.datasets import get_cifar10\n",
    "train_loader, test_loader = get_cifar10(batch_size=128)\n",
    "mu, std = [0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]\n",
    "\n",
    "# Define the model\n",
    "from utils.solvers.fixed_step import FixedStepSolver, FixedStepRK4RegSolver, FixedStepNumericalLyapunovSolver, FixedStepNumericalLyapunovSolverV2\n",
    "from utils.integrators.simple import Euler, ModifiedEuler, RungeKutta4, K2K3L1DistRungeKutta4, K2K3L2DistRungeKutta4, K2K3CosSimRungeKutta4\n",
    "from utils.networks.odenet_2 import OdeNet\n",
    "\n",
    "# Load Adversarial attacks\n",
    "from utils.attacks.fgsm import fgsm_attack\n",
    "from utils.attacks.deepfool import deepfool_attack\n",
    "from utils.attacks.pgd import pgd_attack\n",
    "from utils.attacks.attacks import gaussian_noise_attack, salt_and_pepper_attack, simba_attack\n",
    "\n",
    "# Define experiments\n",
    "experiments = [\n",
    "    # Unregularized baseline\n",
    "    (Euler, FixedStepSolver, 2, None, None),\n",
    "    (Euler, FixedStepSolver, 2, None, None),\n",
    "    (Euler, FixedStepSolver, 2, None, None),\n",
    "    # Lyapunov exponents models\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 5e-2, 1),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 5e-2, 1),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 5e-2, 1),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 2),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 2),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 2),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 3),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 3),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 3),\n",
    "    # Runge Kutta divergence models\n",
    "    (K2K3L2DistRungeKutta4, FixedStepRK4RegSolver, 1, 1e-1, None),\n",
    "    (K2K3L2DistRungeKutta4, FixedStepRK4RegSolver, 1, 1e-1, None),\n",
    "    (K2K3L2DistRungeKutta4, FixedStepRK4RegSolver, 1, 1e-1, None),\n",
    "]\n",
    "\n",
    "for intr, sol, steps, le_reg, vectors in experiments:\n",
    "    for i in range(3):\n",
    "        # Define the model\n",
    "        model = OdeNet(solver=sol, integrator=intr, t0=0.0, t1=1.0, steps=steps, in_channels=3, channels=[64, 128, 256, 512], classes=10, mu=mu, std=std)\n",
    "        model.solver1.n, model.solver2.n, model.solver3.n, model.solver4.n = vectors, vectors, vectors, vectors\n",
    "\n",
    "        # Naming for saving\n",
    "        post_fix = \"%sStep-eps1-leReg%s-Vecs%s-Run%s\" % (str(steps), str(le_reg), str(vectors), str(i))\n",
    "        print(\"\\n\" + model.solver1.name + \"-\" + model.solver1.method.name + \"-\" + post_fix)\n",
    "\n",
    "        # Define the convenient average calculators\n",
    "        time_keeper, train_acc, train_exps, test_acc, test_exps = Average(), Average(), Average(), Average(), Average()\n",
    "\n",
    "        epochs = 20\n",
    "        best_acc = 0\n",
    "        for e in range(epochs):\n",
    "            # Train loop\n",
    "            model.train()\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                s = time.time()\n",
    "                # Convert data proper device, forward pass and calculate loss\n",
    "                data, target = data.to(model.device), target.to(model.device)\n",
    "                pred = model(data)\n",
    "                ce_loss = model.loss_module(pred, target)\n",
    "                \n",
    "                #Take optimizer step\n",
    "                model.optimizer.zero_grad()\n",
    "                if le_reg and model.exps:\n",
    "                    (ce_loss + le_reg * model.exps).backward()\n",
    "                else:\n",
    "                    ce_loss.backward()\n",
    "                model.optimizer.step()\n",
    "\n",
    "                # Update metrics\n",
    "                time_keeper.update(time.time() - s)\n",
    "                train_acc.update(accuracy(pred, target))\n",
    "                if le_reg and model.exps:\n",
    "                    train_exps.update(model.exps.item())\n",
    "            \n",
    "            # Evaluation loop\n",
    "            with torch.no_grad():\n",
    "                for i, (data, target) in enumerate(test_loader):\n",
    "                    data, target = data.to(model.device), target.to(model.device)\n",
    "                    pred = model(data)\n",
    "                    ce_loss = model.loss_module(pred, target)\n",
    "                    test_acc.update(accuracy(pred, target))\n",
    "                    if le_reg and model.exps:\n",
    "                        test_exps.update(model.exps.item())\n",
    "            print('Epoch: %d / %d | Time per iter %.3f | Train acc: %.3f | Train exps: %.3f | Test acc: %.3f | Test exps: %.3f' % (e + 1, epochs, time_keeper.eval(), 100 * train_acc.eval(), train_exps.eval(), 100 * test_acc.eval(), test_exps.eval()))\n",
    "\n",
    "            # Save the model\n",
    "            if test_acc.eval() >= best_acc:\n",
    "                torch.save({'state_dict': model.state_dict()}, 'checkpoint/cifar10/' + model.solver1.name + \"-\" + model.solver1.method.name + \"-\" + post_fix + '.pth')\n",
    "                best_acc = test_acc.eval()\n",
    "\n",
    "            # Reset statistics each epoch:\n",
    "            time_keeper.reset(), train_acc.reset(), train_exps.reset(), test_acc.reset(), test_exps.reset()\n",
    "\n",
    "            # Decay Learning Rate\n",
    "            model.scheduler.step()\n",
    "\n",
    "        # Perform FGSM tests\n",
    "        # Check baseline accuracy\n",
    "        gaussian_noise_attack(model, test_loader, std=0.0)\n",
    "\n",
    "        # Run the random gaussian attack\n",
    "        gaussian_noise_attack(model, test_loader, std=35/255.)\n",
    "\n",
    "        # Run salt and pepper attack\n",
    "        salt_and_pepper_attack(model, test_loader, 0.1)\n",
    "\n",
    "        # Run test for each epsilon\n",
    "        fgsm_attack(model, test_loader, 0.2/255.)\n",
    "\n",
    "        # Run the PGD attack\n",
    "        pgd_attack(model, test_loader, epsilon=4/255., alpha=1/255., iters=20)\n",
    "\n",
    "        # Run DeepFool tests\n",
    "        deepfool_attack(model, test_loader, 10)\n",
    "\n",
    "        # Run black box attack\n",
    "        simba_attack(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "checkpoints = [\n",
    "    (\"FixedStepSolver-Euler-2Step-Run0.pth\", Euler, 2),\n",
    "    (\"FixedStepNumericalLyapunovSolverV2-Euler-2Step-leReg0.1-Vecs2-Run0.pth\", Euler, 2),\n",
    "    (\"FixedStepRK4RegSolver-K2K3L2DistRungeKutta4-2Step-leReg0.01-Vecs0-Run0.pth\", RungeKutta4, 1),\n",
    "]\n",
    "\n",
    "idxs = [0, 160, 40, 190, 215] #[random.randint(0, 256) for _ in range(5)]\n",
    "size = 128\n",
    "\n",
    "width, height = (1 + len(checkpoints)) * size, size * len(idxs) \n",
    "grid = Image.new('RGB', (width, height))\n",
    "\n",
    "with torch.no_grad():\n",
    "    data, target = next(iter(test_loader))\n",
    "\n",
    "    for (path, intr, steps) in checkpoints:\n",
    "        model = OdeNet(solver=FixedStepNumericalLyapunovSolverV2, integrator=intr, t0=0.0, t1=1.0, steps=steps, in_channels=3, channels=[64, 128, 256, 512], classes=10,  mu=mu, std=std)\n",
    "\n",
    "        print(\"\\nCheckpoint: \", path)\n",
    "        model.load_state_dict(torch.load(\"checkpoint/cifar10/\"+path, map_location=torch.device('cpu'))[\"state_dict\"])\n",
    "\n",
    "        # Set loops higher to converge\n",
    "        model.solver1.loops, model.solver2.loops, model.solver3.loops, model.solver4.loops = 10, 10, 10, 10\n",
    "\n",
    "        # Convert data proper device, forward pass and calculate loss\n",
    "        data, target = data.to(model.device), target.to(model.device)\n",
    "        pred = model(data)\n",
    "        for i in idxs:\n",
    "            image = data[i].to('cpu').clone()\n",
    "            img = TF.to_pil_image(image).resize((size, size), Image.ANTIALIAS)\n",
    "            grid.paste(img, (0, idxs.index(i) * size))\n",
    "\n",
    "            # Get vectors\n",
    "            diff = model.solver2.diff[0][i, :, :, :].abs().mean(0).to('cpu')\n",
    "            print(i, diff.sum(), diff.max())\n",
    "\n",
    "            # Scale diff 0 - 1\n",
    "            diff = diff / 1.3\n",
    "\n",
    "            # Make heatmap\n",
    "            heatmap = torch.zeros(size=[3] + list(diff.size()))\n",
    "            heatmap[0, :, :] = 2 * diff\n",
    "            heatmap[1, :, :] = 1 - 2 * torch.abs(diff - 0.5)\n",
    "            heatmap[2, :, :] = 1 - 2 * diff\n",
    "            heatmap = heatmap.clamp(0, 1)\n",
    "\n",
    "            h_img = TF.to_pil_image(heatmap).resize((size, size), Image.ANTIALIAS)\n",
    "            res = Image.blend(img, h_img, alpha=0.6)\n",
    "            grid.paste(res, (size + checkpoints.index((path, intr, steps)) * size, idxs.index(i) * size))\n",
    "\n",
    "    grid.show()\n",
    "    grid.save('figs/grid_test.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, torch\n",
    "from utils.training.training_ops import Average, accuracy, loader_accuracy\n",
    "\n",
    "# Make the training / testing loaders\n",
    "from utils.training.datasets import get_cifar100\n",
    "train_loader, test_loader = get_cifar100(batch_size=128)\n",
    "mu, std = [n/255. for n in [129.3, 124.1, 112.4]], [n/255. for n in [68.2,  65.4,  70.4]]\n",
    "\n",
    "# Define the model\n",
    "from utils.solvers.fixed_step import FixedStepSolver, FixedStepRK4RegSolver, FixedStepNumericalLyapunovSolver, FixedStepNumericalLyapunovSolverV2\n",
    "from utils.integrators.simple import Euler, ModifiedEuler, RungeKutta4, K2K3L2DistRungeKutta4\n",
    "from utils.networks.odenet_2 import OdeNet\n",
    "\n",
    "# Load Adversarial attacks\n",
    "from utils.attacks.fgsm import fgsm_attack\n",
    "from utils.attacks.deepfool import deepfool_attack\n",
    "from utils.attacks.pgd import pgd_attack\n",
    "from utils.attacks.attacks import gaussian_noise_attack, salt_and_pepper_attack, simba_attack\n",
    "\n",
    "# Define experiments\n",
    "experiments = [\n",
    "    # Unregularized baseline\n",
    "    (Euler, FixedStepSolver, 2, None, None),\n",
    "    (Euler, FixedStepSolver, 2, None, None),\n",
    "    (Euler, FixedStepSolver, 2, None, None),\n",
    "    # Lyapunov exponents models\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 1),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 5e-2, 1),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-2, 1),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 2),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 5e-2, 2),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-2, 2),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-1, 3),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 5e-2, 3),\n",
    "    (Euler, FixedStepNumericalLyapunovSolverV2, 2, 1e-2, 3),\n",
    "    # Runge Kutta divergence models\n",
    "    (K2K3L2DistRungeKutta4, FixedStepRK4RegSolver, 1, 1e-1, None),\n",
    "    (K2K3L2DistRungeKutta4, FixedStepRK4RegSolver, 1, 5e-2, None),\n",
    "    (K2K3L2DistRungeKutta4, FixedStepRK4RegSolver, 1, 1e-2, None),\n",
    "]\n",
    "\n",
    "for intr, sol, steps, le_reg, vectors in experiments:\n",
    "    for i in range(3):\n",
    "        # Define the model\n",
    "        model = OdeNet(solver=sol, integrator=intr, t0=0.0, t1=1.0, steps=steps, in_channels=3, channels=[64, 128, 256, 512], classes=100,  mu=mu, std=std)\n",
    "        model.solver1.n, model.solver2.n, model.solver3.n, model.solver4.n = vectors, vectors, vectors, vectors\n",
    "\n",
    "        # Naming for saving\n",
    "        post_fix = \"%sStep-leReg%s-Vecs%s-Run%s\" % (str(steps), str(le_reg), str(vectors), str(i))\n",
    "        print(\"\\n\" + model.solver1.name + \"-\" + model.solver1.method.name + \"-\" + post_fix)\n",
    "\n",
    "        # Define the convenient average calculators\n",
    "        time_keeper, train_acc, train_exps, test_acc, test_exps = Average(), Average(), Average(), Average(), Average()\n",
    "\n",
    "        epochs = 20\n",
    "        best_acc = 0\n",
    "        for e in range(epochs):\n",
    "            # Train loop\n",
    "            model.train()\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "                s = time.time()\n",
    "                # Convert data proper device, forward pass and calculate loss\n",
    "                data, target = data.to(model.device), target.to(model.device)\n",
    "                pred = model(data)\n",
    "                ce_loss = model.loss_module(pred, target)\n",
    "                \n",
    "                #Take optimizer step\n",
    "                model.optimizer.zero_grad()\n",
    "                if le_reg and model.exps:\n",
    "                    (ce_loss + le_reg * model.exps).backward()\n",
    "                else:\n",
    "                    ce_loss.backward()\n",
    "                model.optimizer.step()\n",
    "\n",
    "                # Update metrics\n",
    "                time_keeper.update(time.time() - s)\n",
    "                train_acc.update(accuracy(pred, target))\n",
    "                if le_reg and model.exps:\n",
    "                    train_exps.update(model.exps.item())\n",
    "            \n",
    "            # Evaluation loop\n",
    "            with torch.no_grad():\n",
    "                for i, (data, target) in enumerate(test_loader):\n",
    "                    data, target = data.to(model.device), target.to(model.device)\n",
    "                    pred = model(data)\n",
    "                    ce_loss = model.loss_module(pred, target)\n",
    "                    test_acc.update(accuracy(pred, target))\n",
    "                    if le_reg and model.exps:\n",
    "                        test_exps.update(model.exps.item())\n",
    "            print('Epoch: %d / %d | Time per iter %.3f | Train acc: %.3f | Train exps: %.3f | Test acc: %.3f | Test exps: %.3f' % (e + 1, epochs, time_keeper.eval(), 100 * train_acc.eval(), train_exps.eval(), 100 * test_acc.eval(), test_exps.eval()))\n",
    "\n",
    "            # Save the model\n",
    "            if test_acc.eval() >= best_acc:\n",
    "                torch.save({'state_dict': model.state_dict()}, 'checkpoint/cifar100/' + model.solver1.name + \"-\" + model.solver1.method.name + \"-\" + post_fix + '.pth')\n",
    "                best_acc = test_acc.eval()\n",
    "\n",
    "            # Reset statistics each epoch:\n",
    "            time_keeper.reset(), train_acc.reset(), train_exps.reset(), test_acc.reset(), test_exps.reset()\n",
    "\n",
    "            # Decay Learning Rate\n",
    "            model.scheduler.step()\n",
    "\n",
    "        # Perform FGSM tests\n",
    "        # Check baseline accuracy\n",
    "        gaussian_noise_attack(model, test_loader, std=0.0)\n",
    "\n",
    "        # Run the random gaussian attack\n",
    "        gaussian_noise_attack(model, test_loader, std=35/255.)\n",
    "\n",
    "        # Run salt and pepper attack\n",
    "        salt_and_pepper_attack(model, test_loader, 0.1)\n",
    "\n",
    "        # Run test for each epsilon\n",
    "        fgsm_attack(model, test_loader, 0.2/255.)\n",
    "\n",
    "        # Run the PGD attack\n",
    "        pgd_attack(model, test_loader, epsilon=4/255., alpha=1/255., iters=20)\n",
    "\n",
    "        # Run DeepFool tests\n",
    "        deepfool_attack(model, test_loader, 100)\n",
    "\n",
    "        # Run black box attack\n",
    "        simba_attack(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
