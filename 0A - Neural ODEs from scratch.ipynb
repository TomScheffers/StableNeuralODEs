{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural ODEs from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrators are the basis of every neural ODE and can be found under utils.integrators. The solver is used to integrate between two points in time: t and t + dt. Here are some basic examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The forward Euler method is the most simple first order method (comparable to ResNet step)\n",
    "class Euler():\n",
    "    name = \"Euler\"\n",
    "    order = 1\n",
    "    def step(f, t, dt, y):\n",
    "        return y + dt * f(t, y)\n",
    "\n",
    "# 2. The Modified Euler uses an intermediate step\n",
    "class ModifiedEuler():\n",
    "    name = \"ModifiedEuler\"\n",
    "    order = 2\n",
    "    def step(f, t, dt, y):\n",
    "        k1 = f(t, y)\n",
    "        k2 = f(t + dt, y + dt * k1)\n",
    "        return y + dt * (k1 + k2) / 2\n",
    "\n",
    "# 3. The famous Runge Kutta 4 method uses 4 estimates of the gradient\n",
    "class RungeKutta4():\n",
    "    name = \"RungeKutta4\"\n",
    "    order = 4\n",
    "    def step(f, t, dt, y):\n",
    "        k1 = f(t, y)\n",
    "        k2 = f(t + dt / 2,  y + dt * k1 / 2)\n",
    "        k3 = f(t + dt / 2,  y + dt * k2 / 2)\n",
    "        k4 = f(t + dt,      y + dt * k3)\n",
    "        return y + dt * (k1 + 2 * k2 + 2 * k3 + k4) / 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In turn, solvers are used to take multiple steps using integrators to integrate trajectories and solve the initial value problem. For our usecase, we will only use fixed step solvers, however they can be substituted using adaptive step solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedStepSolver():\n",
    "    def __init__(self, f, t0, t1, method, steps=None, step_size=None, verbose=False):\n",
    "        self.name = \"FixedStepSolver\"\n",
    "        self.f = f\n",
    "        self.t0 = t0\n",
    "        self.t1 = t1\n",
    "        self.method = method\n",
    "        self.exp = None\n",
    "\n",
    "        # Define the step sizes h to go from t0 to t1\n",
    "        assert steps or step_size, \"Either steps or step size should be defined!\"\n",
    "        if steps:\n",
    "            self.hs = [(t1 - t0) / steps for s in range(steps)]\n",
    "        else:\n",
    "            assert step_size <= (t1 - t0), \"Step size should be smaller than integration time!\"\n",
    "            self.hs = [step_size for _ in range(int((t1 - t0) / step_size))]\n",
    "            # Add the residual in the last step, if required\n",
    "            if (t1 - t0) % step_size != 0:\n",
    "                self.hs.append((t1 - t0) - sum(self.hs))\n",
    "        if verbose:\n",
    "            print(\"This solver will be using the following time deltas:\", self.hs)\n",
    "            print(\"This solver will require\", self.method.order * len(self.hs), \"gradient evaluations\")\n",
    "\n",
    "    def integrate(self, y, reset=False):\n",
    "        # For every step h, we integrate using the given method, starting from t0, y\n",
    "        t = self.t0\n",
    "        for h in self.hs:\n",
    "            y = self.method.step(self.f, t, h, y)\n",
    "            t += h\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We can adapt an ResNet (image classifier) to a Neural ODE, by making some small adaptations:\n",
    "1. We downsample the image before feeding it to the ODE Net, instead of within the Residual Blocks\n",
    "2. Use the GradientNet to estimate the gradient at each timestep, an pass that to the solver function (f). The forward pass becomes: x = self.solver.integrate(x)\n",
    "3. Concatenate time at each forward call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by:\n",
    "# https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html#resnet18\n",
    "# https://github.com/rtqichen/torchdiffeq/blob/master/examples/odenet_mnist.py\n",
    "\n",
    "import sys, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.training.tensor_ops import Flatten\n",
    "\n",
    "class GradientNet(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(GradientNet, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(channels + 1, channels, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(channels + 1, channels, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def concat_time(self, t, x):\n",
    "        return torch.cat([x, torch.ones_like(x[:, :1, :, :]) * t], 1)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        x = self.block1(self.concat_time(t, x))\n",
    "        return self.block2(self.concat_time(t, x))\n",
    "\n",
    "class RKNet(nn.Module):\n",
    "    def __init__(self, solver, integrator, t0, t1, classes):\n",
    "        super(RKNet, self).__init__()\n",
    "\n",
    "        # First we want to downsample the image to have an acceptable size for the ODE solver (stride of 2 causes reduction of H/W)\n",
    "        self.sampling = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, stride=1),              # [batch_size, 1, 28, 28] -> [batch_size, 64, 28, 28]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, stride=2, padding=1),  # [batch_size, 64, 28, 28] -> [batch_size, 64, 13, 13]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 4, stride=2, padding=1),  # [batch_size, 64, 13, 13] -> [batch_size, 64, 6, 6]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )  \n",
    "        \n",
    "        # Then we want to apply the magic: model differences so we can use ode solvers\n",
    "        self.gradient = GradientNet(channels=64)\n",
    "        self.solver = solver(self.gradient, t0, t1, integrator, steps=1)\n",
    "\n",
    "        # To make predictions we use a fully connected layer (so convenient :))\n",
    "        self.output = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            Flatten(),\n",
    "            nn.Linear(64, classes)\n",
    "        )\n",
    "\n",
    "        # Define an optimizer so we can call it from the outside\n",
    "        params = list(self.sampling.parameters()) + list(self.gradient.parameters()) + list(self.output.parameters())\n",
    "        self.optimizer = torch.optim.Adam(params, lr=0.1) #torch.optim.SGD(params, lr=0.1, momentum=0.9) #\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Check if GPU is available\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "            self.device = 'cuda'\n",
    "\n",
    "        # Print the amount of parameters\n",
    "        print(\"This model is using %d parameters\" % (sum(p.numel() for p in params if p.requires_grad)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sampling(x)\n",
    "        x = self.solver.integrate(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting .data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Make the training / testing loaders\n",
    "from utils.training.datasets import get_mnist\n",
    "train_loader, test_loader = get_mnist(batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model is using 208138 parameters\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "from utils.solvers.fixed_step import FixedStepSolver\n",
    "from utils.integrators.simple import RungeKutta4\n",
    "model = RKNet(FixedStepSolver, RungeKutta4, 0.0, 1.0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convenient average calculators\n",
    "from utils.training.training_ops import Average, accuracy\n",
    "train_loss, test_loss, test_acc = Average(), Average(), Average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 20 | train loss: 0.218 | test loss: 0.199 | test acc: 93.750\n",
      "Epoch: 2 / 20 | train loss: 0.060 | test loss: 0.077 | test acc: 97.776\n",
      "Epoch: 3 / 20 | train loss: 0.053 | test loss: 0.053 | test acc: 98.287\n",
      "Epoch: 4 / 20 | train loss: 0.044 | test loss: 0.048 | test acc: 98.618\n",
      "Epoch: 5 / 20 | train loss: 0.046 | test loss: 0.150 | test acc: 95.523\n",
      "Epoch: 6 / 20 | train loss: 0.039 | test loss: 0.040 | test acc: 98.778\n",
      "Epoch: 7 / 20 | train loss: 0.038 | test loss: 0.047 | test acc: 98.598\n",
      "Epoch: 8 / 20 | train loss: 0.035 | test loss: 0.045 | test acc: 98.678\n",
      "Epoch: 9 / 20 | train loss: 0.037 | test loss: 0.047 | test acc: 98.538\n",
      "Epoch: 10 / 20 | train loss: 0.030 | test loss: 0.046 | test acc: 98.728\n",
      "Epoch: 11 / 20 | train loss: 0.031 | test loss: 0.103 | test acc: 96.955\n",
      "Epoch: 12 / 20 | train loss: 0.029 | test loss: 0.050 | test acc: 98.478\n",
      "Epoch: 13 / 20 | train loss: 0.032 | test loss: 0.103 | test acc: 97.316\n",
      "Epoch: 14 / 20 | train loss: 0.030 | test loss: 0.049 | test acc: 98.578\n",
      "Epoch: 15 / 20 | train loss: 0.031 | test loss: 0.057 | test acc: 98.488\n",
      "Epoch: 16 / 20 | train loss: 0.024 | test loss: 0.052 | test acc: 98.468\n",
      "Epoch: 17 / 20 | train loss: 0.023 | test loss: 0.036 | test acc: 98.978\n",
      "Epoch: 18 / 20 | train loss: 0.029 | test loss: 0.074 | test acc: 98.167\n",
      "Epoch: 19 / 20 | train loss: 0.024 | test loss: 0.039 | test acc: 99.008\n",
      "Epoch: 20 / 20 | train loss: 0.025 | test loss: 0.042 | test acc: 98.978\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        # Convert data proper device, forward pass and calculate loss\n",
    "        data, target = data.to(model.device), target.to(model.device)\n",
    "        pred = model(data)\n",
    "        loss = model.loss_module(pred, target)\n",
    "        \n",
    "        #Take optimizer step\n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        train_loss.update(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(model.device), target.to(model.device)\n",
    "        pred = model(data)\n",
    "        loss = model.loss_module(pred, target)\n",
    "        test_loss.update(loss.item())\n",
    "        test_acc.update(accuracy(pred, target))\n",
    "\n",
    "    print('Epoch: %d / %d | train loss: %.3f | test loss: %.3f | test acc: %.3f' % (e + 1, epochs, train_loss.eval(), test_loss.eval(), 100 * test_acc.eval()))\n",
    "\n",
    "    # Reset statistics each epoch:\n",
    "    train_loss.reset(), test_loss.reset(), test_acc.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
